"""
This file is a template for the .env file.

Please copy this file to .env and fill in the values.

For more information about configuration options, please refer to the documentation

"""

# ==========================================
# Global configs:
USE_AZURE=False
CHAT_USE_AZURE_TOKEN_PROVIDER=False
EMBEDDING_USE_AZURE_TOKEN_PROVIDER=False
MAX_RETRY=10
RETRY_WAIT_SECONDS=20
# ==========================================

# ==========================================
# Backend Configuration
# ==========================================
BACKEND=rdagent.oai.backend.LiteLLMAPIBackend
# ==========================================


# ==========================================
# Backend Configuration (choose one)
# ==========================================
# 1. Set universal API key
# OPENAI_API_KEY="sk-your-api-key-here"
# CHAT_MODEL="gpt-4o"
# EMBEDDING_MODEL="text-embedding-3-small"
# # Optional: Custom endpoint
# OPENAI_BASE_URL="https://your-endpoint.com/v1"

# 2. Set separate API KEY
# Chat configuration (using LiteLLM)
CHAT_OPENAI_API_KEY="sk-chat-key"
CHAT_OPENAI_BASE_URL="https://xxx-litellm.com/v1"
CHAT_MODEL='gpt-4o'
# Embedding configuration (using other service)
# Use siliconflow as example, pay attention to the **openai/** prefix
EMBEDDING_OPENAI_API_KEY="sk-embedding-service-key"
EMBEDDING_OPENAI_BASE_URL="https://api.siliconflow.cn/v1"
EMBEDDING_MODEL="openai/BAAI/bge-m3"
# ==========================================

# ==========================================
# Other Configuration 
# ==========================================
# CHAT_AZURE_API_BASE=<for_Azure_user>
# CHAT_AZURE_API_VERSION=<for_Azure_user>

# EMBEDDING_AZURE_API_BASE=<for_Azure_user>
# EMBEDDING_AZURE_API_VERSION=<for_Azure_user>

# Cache Setting (Optional):

# Senario Configs:
# ==========================================